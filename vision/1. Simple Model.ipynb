{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da74edff-1220-402d-8bd0-266bfff7458a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load library\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "# Load constants\n",
    "DATA_PATH = \"data/hand-sign-images\"\n",
    "TENSORBOARD_PATH = \"tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62c0c4f9-13cf-455d-96a2-23761eabdae2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe113528-506a-405a-9fc0-8b60eaccc1da",
   "metadata": {},
   "source": [
    "# Checking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a60a1138-cbd7-4c27-bf06-05cb52d1148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder PATH listing for volume Program and Files\n",
      "Volume serial number is 081B-4D30\n",
      "D:.\n",
      "+---.ipynb_checkpoints\n",
      "\\---data\n",
      "    +---.ipynb_checkpoints\n",
      "    \\---hand-sign-images\n",
      "        +---Test\n",
      "        |   +---A\n",
      "        |   +---B\n",
      "        |   +---C\n",
      "        |   +---D\n",
      "        |   +---E\n",
      "        |   +---F\n",
      "        |   +---G\n",
      "        |   +---H\n",
      "        |   +---I\n",
      "        |   +---K\n",
      "        |   +---L\n",
      "        |   +---M\n",
      "        |   +---N\n",
      "        |   +---O\n",
      "        |   +---P\n",
      "        |   +---Q\n",
      "        |   +---R\n",
      "        |   +---S\n",
      "        |   +---T\n",
      "        |   +---U\n",
      "        |   +---V\n",
      "        |   +---W\n",
      "        |   +---X\n",
      "        |   \\---Y\n",
      "        \\---Train\n",
      "            +---A\n",
      "            +---B\n",
      "            +---C\n",
      "            +---D\n",
      "            +---E\n",
      "            +---F\n",
      "            +---G\n",
      "            +---H\n",
      "            +---I\n",
      "            +---K\n",
      "            +---L\n",
      "            +---M\n",
      "            +---N\n",
      "            +---O\n",
      "            +---P\n",
      "            +---Q\n",
      "            +---R\n",
      "            +---S\n",
      "            +---T\n",
      "            +---U\n",
      "            +---V\n",
      "            +---W\n",
      "            +---X\n",
      "            \\---Y\n"
     ]
    }
   ],
   "source": [
    "!tree /a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5639d70-b214-43f4-a482-65d15ae64aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27455 files belonging to 24 classes.\n",
      "Found 7172 files belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=f\"{DATA_PATH}/Train\",\n",
    "    color_mode='grayscale',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(28, 28),\n",
    "    seed=2023,\n",
    ")\n",
    "dataset_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=f\"{DATA_PATH}/Test\",\n",
    "    color_mode='grayscale',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(28, 28),\n",
    "    seed=2023,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffe0bda7-c16a-4c57-935d-1b20b0feb4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 24)\n",
      "(32, 28, 28, 1)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "test_data = dataset_train.take(1)\n",
    "for image, label in test_data.as_numpy_iterator():\n",
    "    print(label.shape)\n",
    "    print(image.shape)\n",
    "    \n",
    "    print(image.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97164b4f-e705-4859-9a80-6d5fec63ad4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4851bbdc-5016-44b8-b68e-96d2989cdbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28,28,1), dtype=tf.float32),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(24)\n",
    "])\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    ")\n",
    "\n",
    "optim = tf.keras.optimizers.Adam(\n",
    "    learning_rate=1e-3\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optim,\n",
    "    loss=loss,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "953f05d8-3635-4b5d-9959-a4a503632da0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "858/858 [==============================] - 11s 12ms/step - loss: 7.8728 - accuracy: 0.3724 - val_loss: 1.8372 - val_accuracy: 0.4629\n",
      "Epoch 2/5\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 1.1722 - accuracy: 0.6368 - val_loss: 1.8358 - val_accuracy: 0.5109\n",
      "Epoch 3/5\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 0.8373 - accuracy: 0.7331 - val_loss: 2.0367 - val_accuracy: 0.5237\n",
      "Epoch 4/5\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 0.6032 - accuracy: 0.8060 - val_loss: 1.4185 - val_accuracy: 0.6364\n",
      "Epoch 5/5\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 0.5402 - accuracy: 0.8272 - val_loss: 1.7456 - val_accuracy: 0.6323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18e589b01f0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=dataset_train,\n",
    "    validation_data=dataset_test,\n",
    "    \n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5df725-b25c-436a-ac6d-4b4b2a6bf2d4",
   "metadata": {},
   "source": [
    "## Let's see the impact of Data Augmentation\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/preprocessing_layers#image_data_augmentation_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "472e1789-735f-468c-8112-10364b4c97dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27455 files belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_train_augmented = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=f\"{DATA_PATH}/Train\",\n",
    "    color_mode='grayscale',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(28, 28),\n",
    "    seed=2023,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0525a8e-852b-4191-8e36-a3cf92597b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "data_augmentation_layers = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.1),\n",
    "        tf.keras.layers.RandomZoom(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_train_augmented = dataset_train_augmented\\\n",
    "                            .map(lambda x, y: (data_augmentation_layers(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "63f8f55a-3aa3-4ac7-b9a7-2c9c43e6fce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "858/858 [==============================] - 16s 18ms/step - loss: 10.1439 - accuracy: 0.1922 - val_loss: 2.2956 - val_accuracy: 0.3349\n",
      "Epoch 2/5\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 2.1260 - accuracy: 0.3287 - val_loss: 2.0710 - val_accuracy: 0.3753\n",
      "Epoch 3/5\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 1.8160 - accuracy: 0.4105 - val_loss: 1.8257 - val_accuracy: 0.4449\n",
      "Epoch 4/5\n",
      "858/858 [==============================] - 16s 18ms/step - loss: 1.6024 - accuracy: 0.4744 - val_loss: 1.4767 - val_accuracy: 0.5046\n",
      "Epoch 5/5\n",
      "858/858 [==============================] - 15s 18ms/step - loss: 1.3508 - accuracy: 0.5478 - val_loss: 1.2922 - val_accuracy: 0.5686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18e6b041090>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28,28,1), dtype=tf.float32),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(24)\n",
    "])\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    ")\n",
    "\n",
    "optim = tf.keras.optimizers.Adam(\n",
    "    learning_rate=1e-3\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optim,\n",
    "    loss=loss,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=dataset_train_augmented,\n",
    "    validation_data=dataset_test,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "81a9a270-5940-4319-aba3-4b93adf24c54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "858/858 [==============================] - 15s 18ms/step - loss: 1.2601 - accuracy: 0.5804 - val_loss: 1.1807 - val_accuracy: 0.6135\n",
      "Epoch 2/5\n",
      "858/858 [==============================] - 16s 18ms/step - loss: 1.1640 - accuracy: 0.6094 - val_loss: 1.3771 - val_accuracy: 0.5782\n",
      "Epoch 3/5\n",
      "858/858 [==============================] - 16s 18ms/step - loss: 1.0458 - accuracy: 0.6515 - val_loss: 1.2392 - val_accuracy: 0.6068\n",
      "Epoch 4/5\n",
      "858/858 [==============================] - 17s 20ms/step - loss: 0.9610 - accuracy: 0.6830 - val_loss: 1.5072 - val_accuracy: 0.5594\n",
      "Epoch 5/5\n",
      "858/858 [==============================] - 18s 21ms/step - loss: 0.8823 - accuracy: 0.7067 - val_loss: 1.6048 - val_accuracy: 0.6022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18e70d8c2b0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=dataset_train_augmented,\n",
    "    validation_data=dataset_test,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1a2f2-0611-4391-beb7-3ef49f23666d",
   "metadata": {},
   "source": [
    "Hmm menggunakan data augmentation memang membuat model lebih stabil dalam belajar (bisa dilihat bahwa accuracy dan val_accuracy mengikuti selama 9 epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bf41f-5ee6-4139-8f3b-fef383552fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
